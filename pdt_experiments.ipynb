{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on Phylo HMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tree_serialisation import load_tree\n",
    "from data_simulation import generate_case, rate_sub_HKY, scale_branches_length\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from felsenstein import pruning\n",
    "from viterbi_sumproduct import viterbi, sum_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First example a toy gene finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SIMULATION PARAMETERS\n",
    "tree_path = \"tree.json\"\n",
    "number_of_nucleotids = 100\n",
    "alphabet = ['A', 'C', 'T', 'G']\n",
    "alphabetSize = len(alphabet)\n",
    "\n",
    "nbState = 4\n",
    "# transition matrix of the toy gene finder\n",
    "A = np.zeros((nbState, nbState))\n",
    "A[0, 1] = 1\n",
    "A[1, 2] = 1\n",
    "A[2, 3] = 0.33\n",
    "A[2, 0] = 1 - A[2, 3]\n",
    "A[3, 3] = 0.33  # 0.9999  # unrealistic ...\n",
    "A[3, 0] = 1 - A[3, 3]\n",
    "\n",
    "# state initial probability\n",
    "b = np.array([0.25, 0.25, 0.26, 0.24])\n",
    "\n",
    "animalNames = [\"dog\", \"cat\", \"pig\", \"cow\", \"rat\", \"mouse\", \"baboon\", \"human\"]\n",
    "n_species = len(animalNames)\n",
    "\"\"\"[...], such as the higher average rate of substitution and the greater\n",
    "transition/transversion ratio, in noncoding and third-codon-position sites\n",
    "than in firstand second- codon-position sites[...]\"\"\"\n",
    "\n",
    "pi = np.zeros((nbState, alphabetSize))\n",
    "# substitution rates for pi 0 and 1 are between 0 and 0.001\n",
    "pi[0] = np.random.rand(alphabetSize) * 0.001\n",
    "pi[1] = np.random.rand(alphabetSize) * 0.001\n",
    "# but between 0 and 0.01 for pi 2 and 3\n",
    "pi[2] = np.random.rand(alphabetSize) * 0.01\n",
    "pi[3] = np.random.rand(alphabetSize) * 0.01\n",
    "pi /= pi.sum(axis=1)[:, None]\n",
    "\n",
    "# translation/transversion rate\n",
    "kappa = np.array([2.3, 2.7, 4.3, 5.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the phylogenetic model from JSON\n",
    "tree = load_tree(tree_path)\n",
    "\n",
    "def sub_tree(tree, list_of_species):\n",
    "    \"\"\"\n",
    "    Prune the tree to keep only keep species in a list\n",
    "    Args :\n",
    "           - tree (dict)\n",
    "           - list_of_species (int list)list of index\n",
    "    \"\"\"\n",
    "    tree_cp = deepcopy(tree)\n",
    "    def treat_node(node):\n",
    "        children = tree[node]  # important for the recursion\n",
    "        if children:  # propagate recirsively\n",
    "            for child in children:\n",
    "                treat_node(child[\"node\"])\n",
    "\n",
    "            for child in children:\n",
    "                new_child = child[\"node\"]\n",
    "                if new_child not in list_of_species and not tree_cp[new_child]:\n",
    "                    # we drop the child\n",
    "                    tree_cp[node].remove(child)\n",
    "                    # discard \"dead leaf\"\n",
    "                    tree_cp.pop(new_child, None)\n",
    "                           \n",
    "    treat_node(max(tree_cp.keys()))\n",
    "   \n",
    "    # now merge useless intermediary node ie with only one son\n",
    "    def merge_unary(node, ancestor_list):\n",
    "        if(len(tree_cp[node])== 1):\n",
    "            child = tree_cp[node][0][\"node\"]          \n",
    "            # if the child has ancestor we can remove _node_\n",
    "            if ancestor_list:\n",
    "                branch_length = tree_cp[node][0][\"branch\"]\n",
    "                parent = ancestor_list[0]\n",
    "                siblings = tree_cp[parent]\n",
    "                for sibling in siblings:\n",
    "                    if sibling['node'] == node:\n",
    "                        sibling['node'] = child\n",
    "                        sibling['branch'] += branch_length\n",
    "                # child ancestor are now exactly node's ancestor\n",
    "                merge_unary(child, ancestor_list)\n",
    "            # if the child has no grand parent but has children\n",
    "            elif tree_cp[tree_cp[node][0][\"node\"]]:\n",
    "                tree_cp[child][0][\"branch\"] += tree_cp[node][0][\"branch\"]\n",
    "                tree_cp.pop(node, None)\n",
    "                merge_unary(child, [node])\n",
    "            tree_cp.pop(node, None)\n",
    "        elif len(tree_cp[node])== 2:\n",
    "            merge_unary(tree_cp[node][0][\"node\"], [node]+ ancestor_list)\n",
    "            merge_unary(tree_cp[node][1][\"node\"], [node]+ ancestor_list)\n",
    "\n",
    "    merge_unary(max(tree_cp.keys()), [])\n",
    "    tree_rn = {}\n",
    "    def rename(node):\n",
    "        # rename nodes so that all indices are betwen 1 2*n -1\n",
    "        children = tree_cp[node] \n",
    "        for child in children:\n",
    "            child_node = child[\"node\"]\n",
    "            child[\"node\"] = sorted(tree_cp.keys()).index(child_node)+1\n",
    "            rename(child_node) # rename child first\n",
    "        # now rename actual node \n",
    "        node_renamed = sorted(tree_cp.keys()).index(node)+1\n",
    "        tree_rn[node_renamed] = tree_cp[node]\n",
    "\n",
    "    rename(max(tree_cp.keys()))       \n",
    "    return tree_rn\n",
    "\n",
    "tree = sub_tree(tree, [1,2,5,6])\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = sub_tree(tree, [1,2,5,6])\n",
    "print(tree)\n",
    "trees = []\n",
    "\n",
    "for j in range(nbState):\n",
    "    trees.append(scale_branches_length(tree, scale=0.1 * random.random()*1.5))\n",
    "\n",
    "\n",
    "\n",
    "strands, states = generate_case(A, b, pi, kappa,\n",
    "                                trees, number_of_nucleotids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_strands(strands):\n",
    "    # Transform strands from ints to strings\n",
    "    str_strands = list()\n",
    "    for strand in strands:\n",
    "        str_strand = \"\"\n",
    "        for acid_int in strand:\n",
    "            str_strand = ''.join([str_strand, alphabet[acid_int]])\n",
    "        str_strands += [str_strand]\n",
    "    # Transform strands in sites\n",
    "    sites = list()\n",
    "    for site_ind in range(number_of_nucleotids):\n",
    "        sites += [''.join([str_strands[species_ind][site_ind] for species_ind in range(n_species)])]\n",
    "    return sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Process likelihoods with Felsenstein's algorithm\n",
    "Qs = rate_sub_HKY(pi, kappa)\n",
    "likelihoods = np.zeros((nbState, number_of_nucleotids))\n",
    "for state in range(nbState):\n",
    "    tree = trees[state]\n",
    "    Q = Qs[state]\n",
    "    p = pi[state]\n",
    "    for site_ind, site in enumerate(sites):\n",
    "        likelihoods[state, site_ind] = pruning(Q, p, tree, site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# VITERBI PARAMETERS\n",
    "S = range(nbState)\n",
    "state_sequence_viterbi = viterbi(S, A, b, likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Precision\n",
    "np.sum(states == state_sequence_viterbi) / number_of_nucleotids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str_strands\n",
    "sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
